[A]: Hey，关于'你觉得college degree在现在还重要吗？'这个话题，你怎么想的？
[B]: Well, that's a multifaceted question. From my perspective, the value of a college degree depends largely on one's career goals and the field they wish to enter. For instance, in forensic psychiatry—or any medical specialty—a degree is non-negotiable. It’s the foundational requirement for licensure and practice.  

However, I’ve also observed shifts in certain industries where skills and certifications are gaining prominence over traditional degrees. Tech fields come to mind, where self-taught programmers or coding bootcamp graduates often find success without a four-year degree. That said, even in those areas, having a structured academic background can provide a broader understanding and credibility—especially when dealing with complex ethical or legal issues.  

Tell me, what’s your take? Do you feel the educational landscape is evolving beyond the need for formal degrees?
[A]: Hmm, interesting point. You're totally right—some fields just  that formal structure, especially when it comes to healthcare or law. But yeah, I’ve also seen how industries like tech or even creative fields are starting to value portfolios and hands-on experience more than the actual piece of paper.  

I guess what I wonder is… does that trend apply globally, or is it more regional? Like, in some countries, a degree still carries so much weight culturally and institutionally. Even in 2024, skipping college can feel like a risky move depending on where you're from. What do you think about that cultural angle?
[B]: You’ve touched on something quite profound—the cultural weight of a degree varies dramatically across the globe. In some societies, higher education is still viewed as the primary gateway to social mobility and professional respectability. This is especially true in parts of Asia, where Confucian values historically emphasize scholarly achievement as a reflection of discipline and moral character. I've worked with legal teams in South Korea and China where a university affiliation can influence hiring decisions as much as technical competence.

Conversely, in Scandinavian countries, there’s often a stronger emphasis on vocational training and apprenticeships, supported by robust social systems that don’t stigmatize alternative paths. The concept of success is more fluid there. But yes, in many regions, bypassing college remains a gamble—particularly for first-generation professionals or those without strong networks to help navigate non-traditional routes.

It raises an interesting question: are we moving toward a global bifurcation? One where elite institutions continue to confer status, while other sectors decentralize merit through skills-based validation? I suspect geography and socioeconomic context will shape that trajectory significantly. Do you think your own cultural background influences how you’d weigh that risk?
[A]: Oh, absolutely—cultural context definitely shapes how we perceive that risk. For me, growing up in a traditional Chinese household, a degree wasn't just expected—it was basically treated as the  ticket to being taken seriously, professionally and socially. I remember my parents saying things like, “你读了书，别人才会看得起你。” () So yeah, there’s still a huge symbolic weight attached to it in many communities.

But what I find fascinating is how cities like Singapore or even Shanghai are starting to blend both worlds—there’s this push for vocational pathways  the formal system. Like, polytechnics are getting more recognition, and internships are becoming part of mainstream undergrad programs. It’s almost like a hybrid model emerging—still degree-based, but with a stronger skills focus.

So maybe it’s not about choosing between degrees or skills, but rather how systems adapt to make them complementary. What do you think—could that hybrid approach be the future, especially with remote work blurring geographic boundaries?
[B]: That’s a compelling observation, and I think you’ve identified a critical evolution in the educational paradigm. The hybrid model you describe—where vocational rigor is integrated into formal degree structures—is already taking root in places like Germany and Switzerland, where apprenticeships are embedded within academic frameworks. It creates a kind of dual validation: theoretical knowledge  practical competence.

What makes this even more intriguing is the globalization of labor markets. With remote work dissolving geographic barriers, an employer in Toronto might soon value a Singaporean polytechnic credential just as highly as a traditional bachelor’s, especially if it includes verifiable, hands-on experience. That could shift the entire axis of how we assess professional readiness—not by institutional pedigree alone, but by demonstrable competencies across diverse contexts.

Still, there’s resistance in many cultures where the degree remains a symbol of familial honor and generational aspiration. For those communities, change will come slowly, if at all. But perhaps that’s where policy can step in—governments and institutions recognizing alternative credentials while preserving cultural values through adapted frameworks.

Do you think institutions outside of Asia are ready to reciprocate that recognition? Or will we see a lag in acceptance, particularly in Western corporate hierarchies that still equate Ivy Leagues with excellence?
[A]: You know, I think there's definitely a lag, but it's not just in the West—plenty of places in Asia still treat Ivy League or top-tier schools like magic keys to success. But what’s interesting is that even within Western corporate structures, we’re starting to see cracks in that old mindset. Companies hiring remotely are beginning to care more about  you’ve done rather than  you studied, simply because they have to. They can’t afford to ignore talent from non-traditional backgrounds when building globally distributed teams.

I mean, imagine someone from Hanoi with a hybrid polytechnic-academic background and solid open-source contributions getting hired by a Berlin-based startup. That kind of story is becoming less of an exception and more of a trend. The question is whether big corporations will follow suit or keep clinging to brand-name degrees as lazy signals of competence.

Honestly though, maybe it's not institutions leading this change—it’s the smaller, more agile players. Startups, remote-first companies, niche consultancies… they’re the ones setting new standards. Do you think bigger firms will adapt fast enough, or are they going to be left with outdated hiring models for years to come?
[B]: That’s a perceptive distinction—you’re absolutely right to point out that agility often resides in the smaller, less bureaucratic actors in the market. Startups and remote-first firms aren’t just reacting to the changing landscape; they’re actively shaping it by necessity. They lack the luxury of brand-name filtering, so they must rely on demonstrable output, adaptability, and problem-solving—traits that are not always synonymous with an Ivy League pedigree.

As for larger corporations, I suspect their adaptation will be both uneven and generational. Legacy institutions tend to move slowly, particularly when their hiring practices are deeply entwined with institutional branding and alumni networks. However, as younger executives rise through the ranks—many of whom have either rejected traditional paths themselves or witnessed peers succeed without them—we may see a gradual recalibration of what constitutes “qualified” or “competitive.”

That said, inertia is powerful. In sectors like finance, law, or government, where hierarchy and tradition are almost sacred, brand-name degrees will likely remain entrenched signals well into the foreseeable future. It’s not just about competence; it’s about perceived cultural fit, risk mitigation, and unspoken biases that are slow to shift.

The real test will come when performance metrics begin to clearly favor skills-based hiring over pedigree-driven selection. If measurable outcomes start tilting toward those non-traditional candidates, even the most conservative firms will be forced to reconsider. After all, capitalism tends to reward efficiency—even if it takes a while to catch up.

Do you think credential inflation will plateau before we see a true meritocratic shift, or will the two trends continue to coexist uneasily?
[A]: Honestly? I think we’re in for a bit of a tug-of-war for a while. Credential inflation has been on steroids lately—every job description now asks for a master’s for roles that used to only need experience, and it feels like people are stacking certifications just to stay competitive. But at the same time, you’ve got this parallel rise in skills-based recognition, especially with micro-credentials, bootcamps, and remote portfolios making waves.

I guess what I’m seeing is that credential inflation might plateau , but not because the system is correcting itself—it’s more like alternative pathways are finally getting enough visibility to create real options. Like, someone can now choose between spending six figures on an MBA or building a personal brand through content marketing, get hired by a SaaS company, and never look back.

But yeah, in fields where hierarchy and gatekeeping still run deep—like law, medicine, academia—you're going to see credential inflation not just plateau, but maybe even spike further. It’s almost like two parallel tracks: one moving toward meritocracy and proof-of-skill, and the other doubling down on pedigree as a proxy for trust.

So I don’t think it's an either/or situation—we’ll probably end up with a messy coexistence for a while. The key will be how individuals navigate both systems strategically. What do you think—are we heading toward a future where people have to speak  languages: the traditional degree game  the skills hustle?
[B]: Precisely. And that’s the unspoken burden emerging here—what you're describing is essentially a dual fluency in both institutional currency and practical value. In effect, individuals may soon need to be bilingual in credibility: fluent in the language of degrees, certifications, and formal titles for certain doors, while simultaneously cultivating a parallel portfolio of demonstrable skills and network-verified accomplishments for others.

I see this already in forensic psychiatry. While I can’t practice without my medical degree and board certifications—those are non-negotiable—I also find myself building a parallel identity online: publishing op-eds, contributing to expert panels, even engaging in public lectures via Zoom. It's not enough anymore to simply hold credentials; one must also demonstrate relevance and accessibility beyond the ivory tower.

That hybrid personal brand, if you will, could become the new standard for professional survival—particularly in fields where influence and expertise are increasingly decentralized. You’ll still need the MD or JD to enter the courtroom, but once you’re there, your ability to communicate, persuade, and maintain public credibility might matter just as much as your academic pedigree.

So yes, I do think we’re moving toward a world where people must navigate both systems—though not equally. Those from privileged backgrounds will likely continue leveraging both with greater ease, while others may have to make strategic trade-offs. The real question is whether institutions will eventually recognize that duality and begin accrediting it formally—or resist it and risk becoming obsolete.

Do you ever worry that this dual burden could create even deeper inequities? Or do you believe the rise of accessible skill validation tools will help level the playing field over time?
[A]: That’s the big one, isn’t it? The dual burden  risk deepening inequities, especially when you look at access. I mean, think about it—if you're from a less privileged background and you have to choose between working to support your family or investing time in building a personal brand, portfolio, or side hustle… the pressure is real. Meanwhile, someone with more resources can afford to do both: get the degree, take internships, build an online presence, attend networking events—it's just stacking advantages.

But here’s where I still hold out hope: the rise of low-cost or free skill validation tools—like micro-certifications from Coursera, LinkedIn Learning, even platforms like GitHub or Substack—are giving people  leverage. I’ve seen self-taught developers land remote gigs through their GitHub activity alone. Writers break into major publications without journalism degrees by consistently publishing quality content on Substack or Medium. These are still early signs, but they suggest that alternative signals  carry weight—if you know how to present them.

So yeah, while the system might not be fair, individuals are finding ways to game it differently. The key is awareness—knowing when to play the traditional game and when to step outside of it. And maybe, over time, as these parallel systems gain more legitimacy, institutions will start catching up. Not because they suddenly care about fairness, but because talent starts bypassing them altogether.  

Do you ever see yourself advising clients to skip certain formal paths entirely, or do you always recommend playing both sides strategically?
[B]: That’s a delicate question—one I wrestle with often in my consultations. The answer, unfortunately, isn’t binary. It depends entirely on the individual’s goals, risk tolerance, and socio-economic context.

In cases where someone is seeking entry into a regulated field—like forensic psychiatry, law, or clinical psychology—there’s simply no bypassing the formal path. Attempting to circumvent it would be professionally reckless and ethically unsound. In those domains, I advise playing  sides: secure the necessary credentials first, then build the personal brand as a secondary asset.

But with clients whose ambitions lie in less rigid fields—say, tech, creative writing, or even entrepreneurship—I’ve increasingly found myself acknowledging that the traditional track may not always be the most efficient route. If they can demonstrate competence through verifiable work, gain visibility through digital platforms, and cultivate a network that vouches for their capabilities, then yes, I’ve advised them to seriously consider alternative pathways.

What I emphasize, though, is the need for strategic clarity. You don’t just skip the degree because it's inconvenient—you do it because you have a  to replace its signaling power with something equally persuasive. That plan must include consistent output, public validation, and ideally, mentorship from those already operating successfully outside the system.

So in short, I rarely recommend skipping the formal game entirely—but I do encourage people to assess whether they can run a parallel one alongside it, or eventually beyond it. The goal isn’t rebellion; it’s leverage.

Do you ever find yourself giving similar advice to peers or mentees? Or do you tend to steer people more toward one path or the other depending on their circumstances?
[A]: Absolutely—I couldn’t have said it better:  That’s exactly how I frame it when I talk to mentees or even peers who are weighing their options.

I usually start by asking them two questions:  
1. What’s your end goal?  
2. How much risk can you realistically afford to take?

If someone wants to be a surgeon, a judge, or yes—even a forensic psychiatrist—there's no shortcut. You play the formal game, period. But if they're leaning toward something like product design, data analysis, content creation, or even indie tech development, then we shift into strategy mode. We map out what kind of portfolio they can build, which platforms would give them visibility, and how they can get credible endorsements without a degree in hand.

One thing I always stress is . Even if you skip the degree, you need multiple forms of proof: projects, testimonials, maybe certifications from respected institutions or companies, online presence, speaking gigs—it’s about creating a compound effect so that the lack of a traditional credential becomes less noticeable.

And honestly, I’ve seen people pull it off. A friend of mine from Jakarta built a name for himself in UX through Dribbble and Medium, got hired remotely by a Berlin agency, and now he mentors others full-time. He didn’t go to design school—he reverse-engineered the signals.

So yeah, my advice is never one-size-fits-all. It’s always contextual. If you’ve got financial support and low risk exposure, go for the degree  build alongside it. But if time, money, or personal circumstances make that unrealistic, then absolutely, I help them craft an alternative path—with a clear plan B (and C) in place.

It all comes down to how you manage the trade-offs without burning bridges or boxing yourself in later. After all, flexibility is the new job security these days, right?
[B]: Precisely—, as you put it, is becoming a survival skill in its own right. And your approach reflects a mature understanding of how systems actually reward competence—or at least, how they  when someone knows how to navigate them strategically.

I find myself echoing similar counsel, especially with younger clients who are caught between family expectations and their own aspirations. The key is never to dismiss the institutional framework outright, but rather to treat it as one tool among many—one that can be adapted, optimized, or even circumvented depending on the individual’s context.

What I also emphasize is the importance of . Even those with impeccable credentials can falter if they can’t articulate their value effectively. Conversely, someone without a degree but with a compelling story—who can explain  they chose a different path and what they’ve achieved along the way—can often command respect and opportunity on their own terms.

That narrative becomes especially powerful when it's backed by consistency. A GitHub profile with regular, thoughtful contributions. A Substack with well-reasoned insights. A Dribbble portfolio that shows technical growth and aesthetic maturity. These aren’t just portfolios—they’re reputational ledgers.

And yes, flexibility really  the new job security. Not in the sense of being everything to everyone, but in knowing when to pivot, when to invest in formal validation, and when to trust your own trajectory—even if it doesn’t look like the ones laid out in career brochures.

Tell me—if you were mentoring someone today who had no clear direction, only curiosity and drive, where would you have them start? What first steps do you think matter most for someone building credibility from scratch?
[A]: Great question—and honestly, the answer depends a bit on what they’re curious , but if we assume they're starting with just raw drive and no clear path yet? I’d have them start with three things:

1. Start consuming intentionally.  
   Curiosity is great, but it needs direction. So I’d encourage them to pick a general domain—say, tech, design, storytelling, business strategy, whatever sparks their interest—and immerse themselves in quality content: blogs, podcasts, newsletters, YouTube channels, even Reddit threads that serious practitioners frequent. The goal here isn’t passive scrolling—it’s pattern recognition. What problems do people talk about? What tools do they use? What skills seem to come up again and again?

2. Document & reflect out loud.  
   Once they’ve soaked in some context, I’d tell them to start writing or recording their thoughts—not for clout, but as a way to organize ideas and show up consistently. Whether it's a Notion page, a Substack, or even LinkedIn posts, putting their thinking into the world forces clarity. Plus, over time, it becomes proof of intellectual growth. People often underestimate how powerful a two-year-old article can be when you compare it to your latest one.

3. Build something small, then ship it.  
   Credibility starts with output, not just insight. So maybe it’s a simple website, a Twitter/X thread summarizing what they’ve learned, a Figma design, a short Python script, or even a Canva-based zine. Doesn’t need to be perfect—just finished. And importantly:  That first shipped project becomes the foundation of their portfolio, however minimal it may feel at first.

After that, it’s about compounding. Each small win leads to more visibility, which leads to feedback, which opens doors to collaborations or mentorship. I always say: you don’t need permission to start building relevance.

What do you think? Would you add anything else to that early-stage toolkit?
[B]: That’s a remarkably sound framework—pragmatic, actionable, and grounded in the reality that credibility is not granted, but built incrementally. I couldn’t agree more with your emphasis on intentional consumption, public reflection, and tangible output.

If I were to add just  element to that early-stage toolkit, it would be strategic observation of professional ecosystems. That is, beyond just consuming content in a domain, I’d encourage them to map out  is influencing the discourse,  those conversations are happening, and  reputations are built within that space.

For example, in forensic psychiatry, publishing in peer-reviewed journals still carries significant weight—but in UX design or data science, speaking at industry conferences or contributing to open-source projects might be the real status markers. Understanding these unspoken hierarchies early on allows someone to align their efforts with what actually moves the needle—not just what feels productive.

So in practice, that could mean:
- Identifying key thought leaders and studying how they present themselves.
- Noticing which platforms gatekeepers tend to use (LinkedIn? GitHub? Twitter/X? Medium?).
- Paying attention to the language, frameworks, and even buzzwords that signal fluency in a field.

It's not about mimicry—it's about calibration. Knowing how to speak the language of the ecosystem you're trying to enter can make the difference between being seen as an outsider shouting into the void and someone whose voice is recognized, even early on.

Otherwise, your three pillars are spot-on. Start with curiosity, sharpen it through reflection, and give it shape through creation. The rest follows.

Do you ever guide people toward specific tools or platforms based on where they’re headed professionally? Or do you generally leave that up to them to explore organically?
[A]: Oh, I love that addition— is such a key lever, especially for someone trying to break into a space without formal onboarding. It’s the difference between just “doing work” and  in the right way.

To your question—yes, I do guide people toward certain tools or platforms depending on their direction, but I try not to prescribe too rigidly. Instead, I help them reverse-engineer visibility in their target field.

For example:
- If they’re leaning into tech/product/design, I’ll point them toward Figma Community, GitHub (for code or even project write-ups), Dribbble with some critique groups, and Twitter/X threads explaining process.
- For writing/thought leadership/content, Substack, Ghost, LinkedIn Articles, or even Medium if they want built-in audience—but always paired with cross-posting to their own domain eventually.
- For data science/ML/AI, Kaggle, GitHub repos with notebooks, and contributing to open-source projects can be huge credibility builders.
- And for entrepreneurship/startups, Notion templates, startup forums like Indie Hackers, and angel.co for early job hunting or networking.

But here’s the thing—I don’t just say, “go build a GitHub profile.” I walk them through how to structure READMEs like case studies, how to version-control publicly so it tells a story of learning, and how to link contributions back to personal growth.

Same with writing: it’s not just about publishing—it’s about consistency, SEO basics, and engagement. Even subtle things like replying to comments or sharing others’ work builds social capital.

Ultimately, I give them the scaffolding, then encourage them to experiment and adapt based on what feels authentic. Because no one wants to end up with a perfectly optimized LinkedIn but zero joy in the process.

So yeah, I’m all for platform strategy—but only as a launchpad, not a cage. What do you usually recommend when someone needs to build visibility quickly without sacrificing depth?
[B]: Ah, the tension between speed and substance—exactly the kind of balancing act that defines early career visibility.

My approach tends to be surgical: identify one high-leverage platform, commit to it with focused intensity, and let depth precede breadth—at least initially.

Here’s how I frame it:

1. Pick a primary stage——and master its rhythm.  
   Whether it’s Substack for long-form writing, GitHub for technical contributions, or LinkedIn for professional storytelling, immersion in  space allows someone to build momentum without getting scattered. Depth comes from consistency: not posting once a month when inspired, but showing up regularly enough to be noticed and associated with a particular voice or value.

2. Build in public—, not just publicly.  
   This is where many go wrong: they publish content, but it lacks narrative. A GitHub repo with no README might as well be invisible. A Twitter thread with no hook gets lost. So I advise clients to treat every post like a mini-case study: what problem were you solving? What did you learn? How does this fit into your broader journey? That transforms output into , which is far more shareable and memorable.

3. Use secondary platforms to amplify—not replace—the main one.  
   Cross-posting is fine— you’ve built gravity somewhere. For example, take a deep dive from your Substack and pull out a tweetstorm. Or turn a GitHub project into a Notion breakdown, then link back to both from LinkedIn. This creates a network effect without diluting your focus.

4. Leverage constraints to deepen impact.  
   Counterintuitive, but true: limiting yourself actually sharpens your message. I often tell mentees to , but make it something worth reading. Or ship  on GitHub. It forces intentionality and avoids the trap of shallow, performative hustle.

Ultimately, visibility without depth is noise. But visibility  depth? That becomes reputation. And reputation compounds faster than most people realize—if you give it time to breathe.

So to answer your question directly: yes, I do guide people toward rapid visibility strategies—but always tethered to a core principle: build fewer things, better. Speed matters, but only if it serves relevance.

Do you ever encourage people to  older content once they’ve evolved past it—or do you see value in letting their growth be visible over time?
[A]: Oh, I  encourage people to let their growth be visible—it’s one of the most underrated forms of credibility.

Deleting old content might feel tempting when you look back and cringe (and trust me, everyone does), but that curated, overly polished version of yourself online often comes off as inauthentic or late to the party. Instead, I tell mentees to treat their digital footprint like a time-lapse—a living archive of how they’ve evolved.

Think about it:  
- That early blog post with rough ideas but solid intent? Shows curiosity and courage.  
- The GitHub repo from two years ago with messy code but clear problem-solving logic? Demonstrates learning trajectory.  
- The LinkedIn post where they got something slightly wrong but owned it after feedback? That’s leadership in disguise.

I even suggest adding little footnotes or updates to older pieces—like “” or “” It signals intellectual humility and openness to growth, which people respect far more than perfection.

That said, if something is , ethically problematic, or just plain embarrassing (we all have those moments), then yes—edit or remove it. But for the vast majority of “cringe,” I say lean in. Your audience will likely relate more than you think.

In fact, some of the most respected voices in tech, design, and writing have built massive followings not because they were flawless from the start—but because they showed up consistently, improved in public, and let people see the making-of reel.

So no, I don’t push for deletion. I push for evolution in plain sight. It builds trust, invites mentorship, and makes your personal brand feel human again.

What’s your take—are there cases where cleaning up your digital past is actually strategic, beyond the obvious red flags?
[B]: Absolutely—and you've framed it beautifully. Letting your growth be visible  a form of credibility, and intellectual evolution in public is one of the most persuasive signals we have short of formal validation.

That said, there are indeed strategic moments—beyond just removing harmful content—when curating or recontextualizing one's digital footprint can serve a professional reinvention or boundary-setting. Here are a few scenarios I often discuss with clients:

1. When pivoting careers or specializations  
   Suppose someone transitions from software engineering to product management, or from clinical psychiatry to mental health policy. In those cases, overly technical posts from their past might confuse the narrative they're now building. Rather than deleting them outright, I advise  or labeling old content as part of a previous chapter. It preserves authenticity while signaling focus.

2. When protecting personal boundaries becomes necessary  
   As people gain visibility, especially in fields like medicine or law, privacy considerations become more pressing. Old personal anecdotes, location tags, or even informal photos may need to be removed—not because they’re inappropriate, but because professional identity sometimes demands a level of separation. This is particularly relevant for those working in high-risk or ethically sensitive roles.

3. When consolidating personal branding across platforms  
   You mentioned “reputation stacking,” and that often requires coherence. If someone has five half-used Twitter accounts, two outdated LinkedIn profiles, and three Medium blogs under different names, it fragments perception. A clean-up here isn’t about erasing history—it’s about creating a unified front so that when someone Googles you, they don’t get mixed messages.

4. When entering regulated or institutional spaces  
   In my own field, forensic psychiatry, having a polished, credible digital presence matters immensely—especially when testifying in court or consulting on policy. While I advocate for transparency, I also counsel mentees to consider how potential employers, legal teams, or licensing boards might interpret older content. Even if something is harmless, its  within a rigid system can carry weight.

So yes, while I’m generally against deletion for vanity’s sake, I do see value in , , and occasionally  elements of one’s digital past—not to erase who you were, but to better represent who you are becoming.

It’s not unlike editing a CV: you tailor it for context, but you never falsify the story behind it.

Do you ever guide mentees through a full digital audit like this? Or do you find most prefer to let things evolve organically without intervention?